Análise de Resultados: Operação SAXPY (Tarefa C)


A análise a seguir baseia-se nos dados coletados para as três versões do algoritmo (v1 Sequencial, v2 SIMD e v3 OMP+SIMD), focando na eficiência da paralelização e nos limites do hardware utilizado.

1. Ganho de SIMD (Vetorização)

Ao comparar a versão v1 (Sequencial) com a v2 (SIMD), observa-se um ganho de desempenho imediato, mesmo em execução single-core.

A diretiva #pragma omp simd permitiu que o compilador utilizasse registradores vetoriais (AVX2), processando múltiplos elementos de ponto flutuante simultaneamente.

Isso reduz o número total de instruções executadas pela CPU para cobrir o mesmo valor de N, resultando em um tempo de execução consistentemente menor para a v2 em relação à v1.


2. Escalabilidade e Eficiência Paralela (v3)

A versão v3 (OMP+SIMD) demonstrou comportamentos distintos dependendo do número de threads (T):

1 a 4: Observou-se um speedup quase linear. Como o processador possui 4 núcleos físicos, cada thread pôde ser alocada em um núcleo exclusivo, maximizando o uso dos recursos de processamento.

4 a 8: O ganho de desempenho continuou, porém de forma sublinear. Isso ocorre devido ao Hyper-Threading, onde as 8 threads lógicas compartilham os recursos dos 4 núcleos físicos. O ganho aqui é menor pois as threads começam a competir por unidades de execução e largura de banda de memória.

16 (O Ponto de Inflexão): Para 16 threads, os gráficos de escalabilidade e boxplot mostram uma perda clara de desempenho (aumento no tempo de execução).


3. Impacto do Overhead e Oversubscription

A degradação observada com 16 threads é um caso clássico de oversubscription (sobrealocação).

Como o hardware dispõe de apenas 8 threads lógicas (conforme verificado no htop), a tentativa de executar 16 threads simultâneas força o Sistema Operacional a realizar constantes trocas de contexto (context switching).

O overhead gerado pelo gerenciamento de threads excedentes (salvamento e restauração de estados de registradores) supera o benefício do paralelismo, resultando em tempos superiores aos observados com 8 ou até 4 threads.

Além disso, a operação SAXPY é inerentemente memory-bound (limitada pela memória). Com 16 threads, a disputa pelo barramento de memória torna-se o gargalo principal, impedindo qualquer ganho de processamento extra.


4. Variabilidade e Warm-up

Os gráficos de boxplot individualizados revelam uma variabilidade maior nas primeiras execuções de cada bloco.

Esse comportamento é atribuído ao warm-up do OpenMP, onde a criação inicial do thread pool consome tempo adicional.

Após as primeiras iterações, os tempos tendem a se estabilizar, como mostrado pela "magreza" das caixas nos boxplots para valores intermediários de threads.


Análise de Resultados: Laço irregular e políticas schedule

